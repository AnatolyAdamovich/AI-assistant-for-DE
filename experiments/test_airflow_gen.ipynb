{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "240e2117",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "src_path = os.path.abspath(os.path.join(os.getcwd(), '..'))\n",
    "if src_path not in sys.path:\n",
    "    sys.path.append(src_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7658cb9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.core.llm_generators.airflow import AirflowDagGenerator\n",
    "from src.core.llm_generators.specification import AnalyticsSpecGenerator\n",
    "from src.config.prompts import prompts\n",
    "from src.config.settings import settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "318ca151",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AnalyticsSpec(business_process=BusinessProcess(name='Анализ продаж интернет-магазина', description='Анализировать продажи и поведение покупателей для повышения выручки и оптимизации маркетинговых кампаний', schedule='0 3 * * *', roles=[{'role': 'Менеджеры по продажам'}, {'role': 'Маркетологи'}, {'role': 'Продуктовый аналитик'}], goals=['Повышение выручки', 'Оптимизация маркетинговых кампаний'], limitations='Ограничения по GDPR'), data_sources=[DataSource(name='orders', description='Таблица заказов', type='database', data_schema={'order_id': 'int', 'product_id': 'int', 'timestamp': 'timestamp', 'customer_id': 'int', 'amount': 'float'}, database='PostgreSQL', access_method='SQL-запросы', data_volume='20000 заказов в день', limitations=None, recommendations=[], connection_params={}), DataSource(name='customers', description='Таблица клиентов', type='database', data_schema={'customer_id': 'int', 'name': 'varchar', 'region_id': 'int', 'age': 'int'}, database='PostgreSQL', access_method='SQL-запросы', data_volume='250000 клиентов', limitations=None, recommendations=[], connection_params={})], metrics=[Metric(name='Общая сумма продаж по дням', description='Сумма продаж за каждый день', calculation_method='SUM(amount) по дням', visualization_method='График', target_value=None, alerting_rules=None), Metric(name='Сумма продаж по регионам', description='Сумма продаж по регионам', calculation_method='SUM(amount) GROUP BY region_id', visualization_method='Диаграмма', target_value=None, alerting_rules=None), Metric(name='Количество уникальных покупателей по регионам', description='Количество уникальных покупателей по регионам', calculation_method='COUNT(DISTINCT customer_id) GROUP BY region_id', visualization_method='Таблица', target_value=None, alerting_rules=None), Metric(name='Средний чек', description='Средний чек по продажам', calculation_method='AVG(amount)', visualization_method='График', target_value=None, alerting_rules=None)], dwh=DWH(database='PostgreSQL', environment='dev', structure='Medallion', limitations='Ограничения по GDPR', connection_params={}, retention_policy={}), transformations=[])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spec_gen = AnalyticsSpecGenerator()\n",
    "filepath = settings.ARTIFACTS_DIRECTORY / \"analytics_spec.yml\"\n",
    "result = spec_gen._from_yml_to_analytics_spec(filepath)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e4112822",
   "metadata": {},
   "outputs": [],
   "source": [
    "airflow_gen = AirflowDagGenerator(analytics_specification=result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8ba12095",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'from datetime import datetime, timedelta\\n\\nfrom airflow.sdk import DAG\\nfrom airflow.operators.bash import BashOperator\\nfrom airflow.operators.python import PythonOperator\\n\\n\\nPROJECT_DIR = \"/opt/airflow/dbt\"\\nDATA_PATH = f\"{PROJECT_DIR}/sample\"\\n\\n\\nDEFAULT_ARGS = {\\n    \"owner\": \"airflow\",\\n    \"depends_on_past\": False,\\n    \"email_on_failure\": False,\\n    \"retries\": 1,\\n    \"retry_delay\": timedelta(minutes=5)\\n}\\n\\n\\n{{ moving_data_from_source_to_dwh }}\\n\\n\\nwith DAG(\\n    dag_id=\"{{ dag_name }}\", \\n    start_date={{ start_date }},\\n    schedule_interval=\"{{ schedule }}\",\\n    max_active_runs=1,\\n    catchup=True\\n) as dag:\\n    \\n    moving_data_from_source_to_dwh = PythonOperator(\\n        task_id=\"moving_data\",\\n        python_callable=moving_data_from_source_to_dwh\\n    )\\n\\n    build_staging_models = BashOperator(\\n        task_id=\"build_staging_models\",\\n        bash_command=f\"dbt run --profiles-dir {PROJECT_DIR} \" \\\\\\n                             f\"--project-dir {PROJECT_DIR} \" \\\\\\n                             f\"--select tag:stage \" \\\\\\n                             f\"--no-version-check \" \\\\\\n    )\\n    \\n    build_intermediate_models = BashOperator(\\n        task_id=\"build_intermediate_models\",\\n        bash_command=f\"dbt run --profiles-dir {PROJECT_DIR} \" \\\\\\n                             f\"--project-dir {PROJECT_DIR} \" \\\\\\n                             f\"--select tag:core \" \\\\\\n                             f\"--no-version-check \" \\\\\\n\\n    )\\n\\n    build_marts_models = BashOperator(\\n        task_id=\"build_marts_models\",\\n        bash_command=f\"dbt run --profiles-dir {PROJECT_DIR} \" \\\\\\n                             f\"--project-dir {PROJECT_DIR} \" \\\\\\n                             f\"--select tag:marts \" \\\\\\n                             f\"--no-version-check \" \\\\\\n    )\\n  \\n    # последовательность задач\\n    moving_data_from_source_to_dwh = moving_data_from_source_to_dwh()\\n    \\n    (\\n        moving_data_from_source_to_dwh\\n        >> build_staging_models\\n        >> build_intermediate_models\\n        >> build_marts_models\\n    )'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "template_path = settings.TEMPLATE_DAG_PATH\n",
    "with open(template_path, \"r\", encoding='utf-8') as f:\n",
    "        pipeline_template = f.read()\n",
    "pipeline_template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dfe1a7bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "code = \"\"\"def moving_data_from_source_to_dwh(**context) -> None:\n",
    "\n",
    "    import pandas as pd\n",
    "    from airflow.hooks.postgres_hook import PostgresHook\n",
    "    from airflow_clickhouse_plugin.hooks.clickhouse import ClickHouseHook\n",
    "\n",
    "    # Подключение к источнику данных PostgreSQL\n",
    "    source = PostgresHook(postgres_conn_id='postgres_source')\n",
    "\n",
    "    # Подключение к аналитическому хранилищу ClickHouse\n",
    "    clickhouse_dwh = ClickHouseHook(clickhouse_conn_id='clickhouse_dwh')\n",
    "\n",
    "    # Извлечение данных из таблицы 'orders'\n",
    "    orders_query = \"SELECT * FROM orders\"\n",
    "    orders_records = source.get_records(orders_query)\n",
    "\n",
    "    # Извлечение данных из таблицы 'customers'\n",
    "    customers_query = \"SELECT * FROM customers\"\n",
    "    customers_records = source.get_records(customers_query)\n",
    "\n",
    "    # Загрузка данных в ClickHouse\n",
    "    clickhouse_dwh.execute(\"CREATE TABLE IF NOT EXISTS orders (order_id Int32, product_id Int32, timestamp DateTime, customer_id Int32, amount Float64) ENGINE = MergeTree() ORDER BY order_id\")\n",
    "    clickhouse_dwh.execute(\"CREATE TABLE IF NOT EXISTS customers (customer_id Int32, name String, region_id Int32, age Int32) ENGINE = MergeTree() ORDER BY customer_id\")\n",
    "\n",
    "    clickhouse_dwh.execute('INSERT INTO orders VALUES', orders_records)\n",
    "    clickhouse_dwh.execute('INSERT INTO customers VALUES', customers_records)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "64c708f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'from datetime import datetime, timedelta\\n\\nfrom airflow.sdk import DAG\\nfrom airflow.operators.bash import BashOperator\\nfrom airflow.operators.python import PythonOperator\\n\\n\\nPROJECT_DIR = \"/opt/airflow/dbt\"\\nDATA_PATH = f\"{PROJECT_DIR}/sample\"\\n\\n\\nDEFAULT_ARGS = {\\n    \"owner\": \"airflow\",\\n    \"depends_on_past\": False,\\n    \"email_on_failure\": False,\\n    \"retries\": 1,\\n    \"retry_delay\": timedelta(minutes=5)\\n}\\n\\n\\ndef moving_data_from_source_to_dwh(**context) -> None:\\n\\n    import pandas as pd\\n    from airflow.hooks.postgres_hook import PostgresHook\\n    from airflow_clickhouse_plugin.hooks.clickhouse import ClickHouseHook\\n\\n    # Подключение к источнику данных PostgreSQL\\n    source = PostgresHook(postgres_conn_id=\\'postgres_source\\')\\n\\n    # Подключение к аналитическому хранилищу ClickHouse\\n    clickhouse_dwh = ClickHouseHook(clickhouse_conn_id=\\'clickhouse_dwh\\')\\n\\n    # Извлечение данных из таблицы \\'orders\\'\\n    orders_query = \"SELECT * FROM orders\"\\n    orders_records = source.get_records(orders_query)\\n\\n    # Извлечение данных из таблицы \\'customers\\'\\n    customers_query = \"SELECT * FROM customers\"\\n    customers_records = source.get_records(customers_query)\\n\\n    # Загрузка данных в ClickHouse\\n    clickhouse_dwh.execute(\"CREATE TABLE IF NOT EXISTS orders (order_id Int32, product_id Int32, timestamp DateTime, customer_id Int32, amount Float64) ENGINE = MergeTree() ORDER BY order_id\")\\n    clickhouse_dwh.execute(\"CREATE TABLE IF NOT EXISTS customers (customer_id Int32, name String, region_id Int32, age Int32) ENGINE = MergeTree() ORDER BY customer_id\")\\n\\n    clickhouse_dwh.execute(\\'INSERT INTO orders VALUES\\', orders_records)\\n    clickhouse_dwh.execute(\\'INSERT INTO customers VALUES\\', customers_records)\\n\\n\\nwith DAG(\\n    dag_id=\"example_dag\", \\n    start_date=datetime(2025, 12, 14),\\n    schedule_interval=\"0 5 * * *\",\\n    max_active_runs=1,\\n    catchup=True\\n) as dag:\\n    \\n    moving_data_from_source_to_dwh = PythonOperator(\\n        task_id=\"moving_data\",\\n        python_callable=moving_data_from_source_to_dwh\\n    )\\n\\n    build_staging_models = BashOperator(\\n        task_id=\"build_staging_models\",\\n        bash_command=f\"dbt run --profiles-dir {PROJECT_DIR} \" \\\\\\n                             f\"--project-dir {PROJECT_DIR} \" \\\\\\n                             f\"--select tag:stage \" \\\\\\n                             f\"--no-version-check \" \\\\\\n    )\\n    \\n    build_intermediate_models = BashOperator(\\n        task_id=\"build_intermediate_models\",\\n        bash_command=f\"dbt run --profiles-dir {PROJECT_DIR} \" \\\\\\n                             f\"--project-dir {PROJECT_DIR} \" \\\\\\n                             f\"--select tag:core \" \\\\\\n                             f\"--no-version-check \" \\\\\\n\\n    )\\n\\n    build_marts_models = BashOperator(\\n        task_id=\"build_marts_models\",\\n        bash_command=f\"dbt run --profiles-dir {PROJECT_DIR} \" \\\\\\n                             f\"--project-dir {PROJECT_DIR} \" \\\\\\n                             f\"--select tag:marts \" \\\\\\n                             f\"--no-version-check \" \\\\\\n    )\\n  \\n    # последовательность задач\\n    moving_data_from_source_to_dwh = moving_data_from_source_to_dwh()\\n    \\n    (\\n        moving_data_from_source_to_dwh\\n        >> build_staging_models\\n        >> build_intermediate_models\\n        >> build_marts_models\\n    )'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "airflow_gen._render_dag(pipeline_template=pipeline_template,\n",
    "                        dag_name=\"example_dag\",\n",
    "                        start_date=\"datetime(2025, 12, 14)\",\n",
    "                        schedule=\"0 5 * * *\",\n",
    "                        moving_data_from_source_to_dwh=code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5086981",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
